{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d2f206-3af7-4029-a90d-c1f7fb2533a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biju/anaconda3/envs/myzoobot/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "from torch import nn, optim\n",
    "from torchinfo import summary\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad9d31a-09a8-43db-83da-9ed442db59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value=1000\n",
    "#np.random.seed(1000)\n",
    "torch.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed(seed_value)\n",
    "torch.cuda.manual_seed_all(seed_value)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.enabled=False\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8874f010-9c87-4ae5-bbf4-d44c8642dceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "image_size = 224 \t\t# Dimension of image ( in pixels )\n",
    "batch_size = 64  \t\t# batch size for training data set 64 to 32\n",
    "val_batch_size = 32 \t\t# batch size for validation data set\n",
    "num_classes = 2\t\t\t# Number of classes\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "class_name = ['L', 'NL']\t# classified input images has to be kept in folders with the same class names\n",
    "num_epochs = 50\t\t\t# \n",
    "patience = 5\n",
    "counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9bd1658-fd69-47c9-b689-6ac6fa146d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'best_model.pt'\t\t#model weight to be saved\n",
    "model_dir = os.path.join(os.getcwd(), 'saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04ddf289-fb06-4418-9b25-d5fa6ee10d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b0e1f5b-fdc1-4037-9fb5-b9241270d3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'images/training/'\n",
    "val_dir = 'images/validation/'\n",
    "test_dir = 'images/testing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54004521-9968-47d6-a11e-658c75292dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.ImageFolder(train_dir, transform=transform)\n",
    "val_data = datasets.ImageFolder(val_dir, transform=transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5feb83f5-0bdf-4b83-a796-6d81b975ad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = len(train_data)\n",
    "steps = math.ceil(sample_size / float(batch_size))\t\n",
    "sample_size_val = len(val_data)\n",
    "val_steps =  math.ceil( sample_size_val/ float(val_batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094937f-b4bb-4021-b2fb-059a1acaed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = timm.create_model(\n",
    "    'hf_hub:mwalmsley/zoobot-encoder-convnext_nano',\n",
    "    pretrained=True,\n",
    "    features_only=True  # gives list of feature maps\n",
    ")\n",
    "\n",
    "# Check number of output channels from last feature map\n",
    "in_channels = encoder.feature_info[-1]['num_chs']\n",
    "print(\"Last feature map channels:\", in_channels)\n",
    "\n",
    "# Define custom classifier head\n",
    "class CustomHead(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)  # [B, C, H, W] → [B, C, 1, 1]\n",
    "        self.fc1 = nn.Linear(in_channels, 128)\n",
    "        self.drop1=nn.Dropout(0.2)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.drop1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Combine encoder and head\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, encoder, num_classes):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.head = CustomHead(in_channels, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # encoder returns list of features — take last feature map\n",
    "        x = self.encoder(x)[-1]\n",
    "        x = self.head(x)\n",
    "        return x\n",
    "\n",
    "model = Classifier(encoder, num_classes)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653e16f7-2be2-428e-adbf-1bf24a9e8d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "    \n",
    "# Access underlying ConvNeXt model\n",
    "base_model = model.encoder  # unwrap the FeatureListNet\n",
    "\n",
    "# Unfreeze last two stages\n",
    "for stage in [base_model.stages_3,base_model.stages_2]:\n",
    "    for param in stage.parameters():\n",
    "        param.requires_grad = True\n",
    "\n",
    "# Always keep classifier head trainable\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3ee3dd-3a00-4472-b779-15ee0be1a0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "\n",
    "layer_decay = 0.5\n",
    "params = [\n",
    "    {'params': model.head.parameters(), 'lr': lr * (layer_decay ** 0)}, \n",
    "    {'params': base_model.stages_3.parameters(), 'lr': lr * (layer_decay ** 1)}, \n",
    "    {'params': base_model.stages_2.parameters(), 'lr': lr * (layer_decay ** 2)}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639df5d6-777e-421f-a43d-8c1eb6654ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params, weight_decay=0.05)\n",
    "criterion = nn.CrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3645fc7-ef74-4537-b718-7a44311275a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, input_size=(1, 3, image_size, image_size))\n",
    "# ---- Visualize model graph ----\n",
    "dummy_input = torch.randn(1, 3, image_size, image_size).to(device)\n",
    "output = model(dummy_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a63f26-371d-434d-ad72-2372ecbaf415",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses, val_losses, val_accuracies, train_accuracies = [], [], [], []\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, correct_train, total_train = 0.0, 0.0,0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct_train += (preds == labels).sum().item()\n",
    "        total_train += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    train_acc = 100 * correct_train / total_train\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct, total = 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "    val_acc = 100 * correct / total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}% | \")\n",
    "\n",
    "    #scheduler.step(val_loss)\n",
    "\n",
    "\n",
    "    # Early stopping & checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(),model_name)\n",
    "        print(\"✅ Saved best model\")\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        print(f\"⏳ Early stopping patience: {counter}/{patience}\")\n",
    "        if counter >= patience:\n",
    "            print(\"Early stopping triggered\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96db668b-04ca-4ed6-b793-1e47c00e6b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_dir = './saved_model'\n",
    "model_name = 'finetuned_zoobot.pt'\n",
    "\n",
    "if not os.path.isdir(model_dir):\n",
    "    os.makedirs(model_dir)\n",
    "\n",
    "model_path = os.path.join(model_dir, model_name)\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
