{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e308b3-e430-4a89-bade-08cf4df5772c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import warnings\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform\n",
    "from keras.layers import Input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d37ff46-a308-42df-888d-2a06758bf3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = models.load_model('/home/biju/saving_outputs/model_2_careful_pictures/trial_1/best_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a07da467-ba54-4777-b9d5-53c4fc187243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the sequential layer into a functional\n",
    "inputs = Input(shape=(256, 256, 3))\n",
    "outputs = model_new(inputs)\n",
    "model_new = Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4851c96-5cbb-494f-a65d-95646ab6a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 256, 256, 3)]     0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 2)                 24736514  \n",
      "=================================================================\n",
      "Total params: 24,736,514\n",
      "Trainable params: 24,735,810\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#printing the summary of the loaded model based on alexnet architecture (discussed in paper)\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b709165-07b4-40a9-89f9-4186d6eb1f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: conv2d — Conv2D\n",
      "1: max_pooling2d — MaxPooling2D\n",
      "2: batch_normalization — BatchNormalization\n",
      "3: conv2d_1 — Conv2D\n",
      "4: max_pooling2d_1 — MaxPooling2D\n",
      "5: batch_normalization_1 — BatchNormalization\n",
      "6: conv2d_2 — Conv2D\n",
      "7: conv2d_3 — Conv2D\n",
      "8: conv2d_4 — Conv2D\n",
      "9: max_pooling2d_2 — MaxPooling2D\n",
      "10: flatten — Flatten\n",
      "11: dense — Dense\n",
      "12: dropout — Dropout\n",
      "13: dense_1 — Dense\n",
      "14: dropout_1 — Dropout\n",
      "15: dense_2 — Dense\n"
     ]
    }
   ],
   "source": [
    "#printing different layers\n",
    "inner_seq = model_new.get_layer('sequential')\n",
    "for i, layer in enumerate(inner_seq.layers):\n",
    "    print(f\"{i}: {layer.name} — {layer.__class__.__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172f498-cd3e-422c-8b86-bbc7afda187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d73901-ed65-4a6c-a40e-a98bd55e1382",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_image=np.array(img).astype('float32') / 255.0 #normalize\n",
    "np_image = transform.resize(np_image, (256, 256, 3), anti_aliasing=True) #resizing to 256 x 256\n",
    "image = np.expand_dims(np_image, axis=0) #adding batch dimension\n",
    "\n",
    "predict = model_new.predict(image)\n",
    "print(\"Raw Prediction:\", predict)\n",
    "print(\"Prediction Shape:\", predict.shape)\n",
    "\n",
    "# Get the predicted class index\n",
    "pred_class = np.argmax(predict, axis=1).item()\n",
    "print(\"Predicted Class:\", pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22643710-47d2-4e9a-b1c9-10cb759cff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conenv)",
   "language": "python",
   "name": "conenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
